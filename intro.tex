%% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------


\chapter{Introduction}
Image segmentation is a central task in biomedical image processing and image analysis. It can be used for detecting various diseases, shape diagnosis etc. The dataset which we are trying to segment is electron microscopic (EM) images of liver tissue. The dataset consists of a 3D stack of 2D slices of liver tissue as shown in figure 1.1. The image stack was generated at EMEZ (Electron Microscopy ETH ZÃ¼rich) autonomously by iter-
atively cutting off a slice of the sample and scanning the cut face. With very little
interaction, the apparatus produced an output of 458 slices in 20 hours. The focus of this thesis to compare and analyze different segmentaion methods to segment objects in histology images. In the following section, we describe the difficulties faced in segmentation of the histology images and give an overview of the methods used for segmentation. 

\begin{figure}[h!] \label{fig:3dstack}
\centering
 \includegraphics[width=0.8\linewidth]{figures/3d_stack.png}
\caption{A 3D image stack of liver tissue, output from a scanning electron microscope.
The stacks contains 458 2D images with a resolution of 1890x1952 pixel each.}
\end{figure}



 Nowadays, with the use of fully-convolutional networks, the segmentation can be obtained for a complete image in one forward pass. This helps in using the local as well as contextual information for segmentation. Currently, the benchmark performance in terms of accuracy is achieved by the use of convolutional neural networks (CNN). The neural networks are specialized to learn feature maps from the examples provided and specific to the task at hand. These networks require a huge amount of training data: images and ground truth i.e. label for each pixel in the input image; to train the network from scratch. In literature, we can find different architectures of neural networks specially designed for the task of segmentation, one of the popular architecture is U-Net \cite{unet}. This approach works well for tasks where we can find a significant number of images and can train a neural network. However, this poses a difficulty when we are trying to segment objects in microscopic images.


\begin{figure}[h!] \label{fig:3dstack}
\centering
 \includegraphics[width=0.8\linewidth]{figures/vesicles.png}
\caption{Example of Manual annotations of different objects in liver tissue.}
\end{figure}


\section{Segmentation of Histology Images}
 We can observe following traits in EM images:
\begin{itemize}
\item High variability between images: The images to be segmented may be entirely different i.e. having fixed objects as in liver tissue or having layers to segments as in neuron tissue. The objects to be segmented may differ completely from being smooth (round vesicles) to branched (neurons). This prohibits the use of one dataset to train a network for another dataset and thus, restricting the availability of images.
\item High variability between objects to segment: The objects to be segmented vary significantly in shape, size, and texture in different images. We can observe few objects of interest in figure 1.2.
\item High variability between goals: Even for a single image, the goal of the segmentation can be totally different. The images annotated for one object can not be used again for training purpose.
\end{itemize}
These characteristics of EM images make it very difficult to fully annotate each object of interest and is extremely time-consuming for experts. Here for our task, we are interested to segment vesicles, as shown in figure 1.3. The difficulty in annotating different vesicles of undefined shapes and sizes can be observed in Figure 1.3. To add to this complexity, the experts are uncertain about the existence of vesicles in certain parts of images and sometimes, even one expert annotates differently at different times. The difference in annotations can be observed for different experts and also for annotations of the same image by the same expert, as shown in figure 1.4. For example, we can observe differences in rectangular boxes in figure 1.4. This uncertainty has been analyzed in literature and researchers have tried to come up with different methods to get one ground truth mask from these multiple annotations by experts. We can use STAPLE \cite{staple} algorithm or union or majority voting to derive reference mask. The reference mask derived for one slice using STAPLE and union is shown in figure 1.5\par



\begin{figure}[h!] \label{fig:2dslice}
\centering
 \includegraphics[width=0.7\linewidth]{figures/ex_slice.pdf}
\caption{Cropped part of slice 15 and its ground truth annotation by an expert.}
\end{figure}

\begin{figure}[h!] \label{fig:diffexperts}
 \includegraphics[width=1.0\linewidth]{figures/different_expert.pdf} \\
  \includegraphics[width=1.0\linewidth]{figures/same_expert.pdf}
\caption{Upper row: Annotation of an slice by different experts. Bottom row: Multiple annotations of an slice by same expert. One example of difference can be observed in bounding boxes.}
\end{figure}

\begin{figure}[] \label{fig:ref}
\centering
 \includegraphics[width=0.7\linewidth]{figures/staple.pdf}
\caption{Grounth truth mask derived from multiple annotaions using 2 different methods}
\end{figure}

\section{Focus of this thesis}
Nowadays, it is common to train deep neural networks (DNN) using transfer learning to compensate for the lack of enough data for training. Recently, Shelmar et al. \cite{long:2014} designed a "fully convolutional" network that takes input of arbitrary size and produces segmented output for a complete image. They adapted contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. Similar to this, we use and fine-tune network explained in Caelles et al. \cite{osvos}. This paper tackles the task of \textbf{semi-supervised} video object segmentation, i.e., segment an object in a video, given fully annotated mask of the object in the first frame. This task can be considered to be similar to segmenting objects in a 3D stack of slices. We try to fine-tune the network using fully annotated objects in few slices in the stack. We describe the details and observations in Section 2.

The use of pre-trained networks makes it possible to use DNN even with small amount of training data. But still to train the DNN, we need to provide fully annotated masks for objects of interest for all training images and this comes out to be a tedious and difficult task as explained above. In addition, the presence of multiple objects of different shape and sizes makes it even more difficult and time-consuming. Imagine 1000 cells in a 2D slice and possibility to manually annotate all these cells of undefined shapes! This provides us with the option of annotating few objects and train networks using either cropped images or treating rest of image as background. Or we can use semi-supervised learning using partial annotations. In literature, we can find various methods to use these partial annotations to classify each pixel as foreground or background. For example, Santner \cite{santner:2009} describes the use of Random forests (RF) for image segmentation using partial annotations. In this thesis, we try to discover the effect of annotation budget i.e. the number of pixels to annotate and the accuracy achieved. We also try to learn which pixels to annotate to use our annotation budget efficiently. 

These methods only learn pixel level information and are uncertain for the maximum of pixels i.e. the probability of foreground learned is not binary but lies between 0 and 1. In literature, different approaches can be found to use prior information to compensate for data and for the uncertainty of estimators. The most common are to use Conditional random fields (CRFs) or graph cuts to regularize the probability learned. We solve this problem using a prior in \textbf{Bayesian framework}. Santner \cite{santner:2009} uses a weighted total variation as prior and Random forests to learn likelihood. Ranftl \cite{ranftl:2014} uses CNN to learn unary and edge potential and combine this information to get segmentation mask using graph cuts. For our task, we implement the method described in the master thesis of Eugster \cite{dominic}. In Eugster \cite{dominic}, they try to learn likelihood using Random forests and prior as an isotropic total variation (TV). They use a non-linear cost function to formulate likelihood from probabilities learned from Random forests. This is quite different to the common approach of using probabilities directly as likelihood to combine with prior. A majority of researchers using CNN use a linear cost function to implement prior with help of CRFs. In this thesis, we analyze and compare these different cost functions. We try to observe the advantage of using these cost functions in different scenarios. For images as 3D stacks, it is observed to be a difficult task and computationally efficient to encode 3D information in models as CNN or RF for learning likelihood. Also, it is common practice to use prior information in 2D. Thus, we also try to observe benefits of using 3D isotropic total variation in case of 3D stacks. \par

In summary, we use a Bayesian approach with RF to parametrize likelihood and isotropic TV as prior to predict segmentation mask for a given image. This gives us chance to generate fully annotated segmentation masks and train CNN to obtain better accuracy. The common problem for use of prior is the choice of appropriate scaling to couple likelihood and prior costs. Ranftl \cite{ranftl:2014} coupled the prior cost function with the likelihood cost function obtained from CNN. They optimized the final loss function to obtain optimal values for network parameters (weights and biases) and regularization parameter. Riegler \cite{riegler:2016} \cite{riegler1:2016} proposed a method to implement TV as specialized layers in CNN and trained the complete model, CNN + TV, together. This motivated us to replace RF with CNN and try to learn pre-trained fully convolutional network from partial annotations. We were able to restructure cross-entropy loss to compute loss for partial annotations. \newline
Finally, we also showed the advantage of using iterative semi-interactivity for efficient use of annotation budget and also to be able to provide an opportunity to experts to improve learning method according to their specific requirements.

\section{Thesis Organization}
The thesis is divided mainly into two sections: segmentation using fully annotated objects and segmentation using partial annotations. The segmentation using full annotations is described in Section 2. The latter method is described in Section 3. In section 3.1, we describe the improvement in segmentation mask for increased labeling effort. We introduce the use of prior and variational methods in section 3.2. In section 3.3, we introduce use CNN to learn from partial annotations. Finally, in the last section, we conclude this thesis and lay out future work that can be done.


