%% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------

\newpage
\vspace{3cm}

\chapter*{Abstract}
The problem of image segmentation has been tackled using various approaches and now, use of Convolutional Neural Networks(CNN) have set new benchmarks for all problems. With the access to GPUs and huge data, these networks can be trained very fast to give best results. In addition, use of fully convolutional nets have stepped up performance both in terms of accuracy and speed. The only bootleneck that can be thought for use of CNN is availabitlity of data for training. This includes both images and ground truth labels for training. \par 
In this thesis, we try to segment an image of liver tissue acquired using Electron microscope and  focus on segmenting vesicles in images. The focus of this thesis is to analyze change in segmentation score with labelling effort. We want to do this analysis because the cellular structure in microscopic images are difficult and time consuming to annotate. Firstly, we make use of fully annotated objects to fine-tune pretrained network, described as OSVOS and observe the trade off between amount of training data required and accuracy.
The manual annotations provided by experts are different for same image. This motivates us to provide a method where the experts can make changes in results easily and train interactively. Due to excessive effort required for annotation budget, we decided to use Bayesian approach to solve our segmentation problem. We used simple isotropic total variation as prior and parametrized likelihood using an estimator. We used Random forest to learn likelihood using different cost functions. We compared few cost functions and showed robustness of \textit(anti-nll) cost function for varying data and regularization parameter. \par
Using random forest and total variation, we analysed the amount of annotations required for expected accuracy. We used scribbles as partial annotation to train random forest. We showed that how a given annotation budget can be used to generate best results. We conducted this experiment by dividing manual scribbles into "easy" and "hard" class on basis of effort required for annotation. We observed that better results can be obtained if we use our scribbles intelligently. In addition, we observed boost in accuracy due to use of variational method. This also motivates use of prior to compensate for lack of data.\par
Finally, we used \textbf{cross-entropy scribble loss} to use pre-trained deep neural network to learn from scribbles. This was motivated with the emergence of various approached to couple CNN with variational methods. We concluded with stating that layered implementation of variational methods can be coupled with CNN and can be used with ease with CNNs.